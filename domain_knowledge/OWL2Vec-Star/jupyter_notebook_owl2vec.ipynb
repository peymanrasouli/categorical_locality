{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75a6c5ab",
   "metadata": {},
   "source": [
    "## Running OWL2Vec*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2658935d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Access the ontology ...\n",
      "INFO: There are 1945 triples in the ontology\n",
      "INFO: Calculate the ontology projection ...\n",
      "INFO: Creating ontology graph projection...\n",
      "INFO: \tExtracting subsumption triples\n",
      "INFO: \t\tTime extracting subsumption: 0.09686398506164551 seconds \n",
      "INFO: \tExtracting equivalence triples\n",
      "INFO: \t\tTime extracting equivalences: 0.020931243896484375 seconds \n",
      "INFO: \tExtracting class membership triples.\n",
      "INFO: \t\tTime extracting class membership: 0.27606821060180664 seconds \n",
      "INFO: \tExtracting sameAs triples\n",
      "INFO: \t\tTime extracting sameAs: 0.007113456726074219 seconds \n",
      "INFO: \tExtracting triples associated to hasBase\n",
      "INFO: \t\tTime extracting triples for property: 0.11680412292480469 seconds \n",
      "INFO: \tExtracting triples associated to hasIngredient\n",
      "INFO: \t\tTime extracting triples for property: 0.12323284149169922 seconds \n",
      "INFO: \tExtracting triples associated to isBaseOf\n",
      "INFO: \t\tTime extracting triples for property: 0.12279510498046875 seconds \n",
      "INFO: \tExtracting triples associated to hasCountryOfOrigin\n",
      "INFO: \t\tTime extracting triples for property: 0.11377763748168945 seconds \n",
      "INFO: \tExtracting triples associated to isIngredientOf\n",
      "INFO: \t\tTime extracting triples for property: 0.11154794692993164 seconds \n",
      "INFO: \tExtracting triples associated to hasSpiciness\n",
      "INFO: \t\tTime extracting triples for property: 0.14375591278076172 seconds \n",
      "INFO: \tExtracting triples associated to hasTopping\n",
      "INFO: \t\tTime extracting triples for property: 0.2053215503692627 seconds \n",
      "INFO: \tExtracting triples associated to isToppingOf\n",
      "INFO: \t\tTime extracting triples for property: 0.12293863296508789 seconds \n",
      "INFO: \tExtracting data property assertions\n",
      "INFO: \t\tTime extracting data property assertions: 0.00044345855712890625 seconds \n",
      "INFO: \tExtracting complex equivalence axioms\n",
      "INFO: \t\tTime extracting complex equivalence axioms: 3.704533338546753 seconds \n",
      "INFO: \tExtracting annotations.\n",
      "INFO: \t\tTime extracting annotations: 0.598853588104248 seconds \n",
      "INFO: Projection created into a Graph object (RDFlib library)\n",
      "INFO: Projection saved into turtle file: ./cache/projection.ttl\n",
      "INFO: Extract classes and individuals ...\n",
      "INFO: Extract axioms ...\n",
      "INFO: Extract annotations ...\n",
      "INFO: Generate URI document ...\n",
      "INFO: Extracted 3350 walks for 104 seed entities\n",
      "INFO: Extracted 279 axiom sentences\n",
      "INFO: Generate literal document ...\n",
      "INFO: Extracted 34 annotation sentences\n",
      "INFO: Generate mixture document ...\n",
      "INFO: URI_Doc: 3629, Lit_Doc: 12069, Mix_Doc: 3629\n",
      "INFO: Time for document construction: 7.36484169960022 seconds\n",
      "INFO: Train the language model ...\n",
      "INFO: collecting all words and their counts\n",
      "INFO: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO: PROGRESS: at sentence #10000, processed 58659 words, keeping 682 word types\n",
      "INFO: collected 784 word types from a corpus of 113133 raw words and 19327 sentences\n",
      "INFO: Creating a fresh vocabulary\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 784 unique words (100.0%% of original 784, drops 0)', 'datetime': '2022-04-03T17:49:15.616052', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 113133 word corpus (100.0%% of original 113133, drops 0)', 'datetime': '2022-04-03T17:49:15.616522', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: deleting the raw counts dictionary of 784 items\n",
      "INFO: sample=0.001 downsamples 55 most-common words\n",
      "INFO: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 53122.766305690864 word corpus (47.0%% of prior 113133)', 'datetime': '2022-04-03T17:49:15.622461', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'prepare_vocab'}\n",
      "INFO: estimated required memory for 784 words and 100 dimensions: 1019200 bytes\n",
      "INFO: resetting layer weights\n",
      "INFO: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-04-03T17:49:15.632628', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'build_vocab'}\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 784 vocabulary and 100 features, using sg=1 hs=0 sample=0.001 negative=25 window=5 shrink_windows=True', 'datetime': '2022-04-03T17:49:15.633113', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 1 : training on 113133 raw words (53070 effective words) took 0.2s, 277862 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 2 : training on 113133 raw words (53311 effective words) took 0.2s, 287555 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 3 : training on 113133 raw words (53015 effective words) took 0.2s, 277155 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 4 : training on 113133 raw words (52883 effective words) took 0.2s, 292745 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 5 : training on 113133 raw words (53129 effective words) took 0.2s, 288950 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 6 : training on 113133 raw words (53164 effective words) took 0.2s, 266382 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 7 : training on 113133 raw words (53198 effective words) took 0.2s, 282133 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 8 : training on 113133 raw words (53113 effective words) took 0.2s, 286650 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 9 : training on 113133 raw words (53141 effective words) took 0.2s, 298462 effective words/s\n",
      "INFO: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO: EPOCH - 10 : training on 113133 raw words (53232 effective words) took 0.2s, 296483 effective words/s\n",
      "INFO: Word2Vec lifecycle event {'msg': 'training on 1131330 raw words (531256 effective words) took 1.9s, 273836 effective words/s', 'datetime': '2022-04-03T17:49:17.573646', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'train'}\n",
      "INFO: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=784, vector_size=100, alpha=0.025)', 'datetime': '2022-04-03T17:49:17.574091', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'created'}\n",
      "INFO: Time for learning the language model: 1.9904305934906006 seconds\n",
      "INFO: Word2Vec lifecycle event {'fname_or_handle': './cache/output/ontology.embeddings', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2022-04-03T17:49:17.575456', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'saving'}\n",
      "INFO: not storing attribute cum_table\n",
      "INFO: saved ./cache/output/ontology.embeddings\n",
      "INFO: storing 784x100 projection weights into ./cache/output/ontology.embeddings.txt\n"
     ]
    }
   ],
   "source": [
    "from owl2vec_star import owl2vec_star\n",
    "\n",
    "\n",
    "#Parameters:\n",
    "# ontology_file\n",
    "# config_file\n",
    "# uri_doc\n",
    "# lit_doc\n",
    "# mix_doc\n",
    "gensim_model = owl2vec_star.extract_owl2vec_model(\"./case_studies/pizza/pizza.owl\", \"./default.cfg\", True, True, True)\n",
    "\n",
    "output_folder=\"./cache/output/\"\n",
    "\n",
    "#Gensim format\n",
    "gensim_model.save(output_folder+\"ontology.embeddings\")\n",
    "    #Txt format\n",
    "gensim_model.wv.save_word2vec_format(output_folder+\"ontology.embeddings.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a78df2",
   "metadata": {},
   "source": [
    "## Loading embeddings and getting similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fdbcf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: loading KeyedVectors object from ./cache/output/ontology.embeddings\n",
      "INFO: loading wv recursively from ./cache/output/ontology.embeddings.wv.* with mmap=r\n",
      "INFO: setting ignored attribute cum_table to None\n",
      "INFO: Word2Vec lifecycle event {'fname': './cache/output/ontology.embeddings', 'datetime': '2022-04-03T18:04:36.338347', 'gensim': '4.1.2', 'python': '3.8.10 (default, Mar 15 2022, 12:22:08) \\n[GCC 9.4.0]', 'platform': 'Linux-5.4.0-107-generic-x86_64-with-glibc2.29', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector for 'pizza'\n",
      "[ 0.0743243   0.19293383  0.30593383  0.3958468   0.05247805 -0.49616787\n",
      " -0.15440564 -0.08259189 -0.3909355  -0.28168628 -0.19477333  0.04056818\n",
      " -0.00485978 -0.07915749  0.00390384 -0.1433732   0.03623685 -0.43204474\n",
      " -0.4556869   0.24026614 -0.03671354 -0.10615446  0.30385765  0.48483336\n",
      "  0.3556914  -0.29235455  0.36101553  0.7010289  -0.27350602 -0.05840959\n",
      " -0.6465348  -0.13692051 -0.50201017  0.0198493   0.29761103 -0.00551832\n",
      "  0.16487654  0.00621    -0.47335416 -0.04636294  0.40056136 -0.00120556\n",
      " -0.23578557 -0.08001129  0.43851233 -0.10489195  0.13952565  0.7221025\n",
      "  0.5165394   0.02995601  0.6822823  -0.15879251 -0.09926439 -0.3754523\n",
      "  0.4157486  -0.12630604  0.05572855  0.24061187  0.3542874   0.04792669\n",
      "  0.23201172  0.2330062  -0.14037839 -0.01443206  0.28566542 -0.05792437\n",
      "  0.0668584  -0.2510384  -0.26868662  0.06789784  0.33012024 -0.34459594\n",
      " -0.43841365  0.13969836  0.22876818  0.05193956  0.2464987  -0.54647446\n",
      "  0.34375235 -0.36977416 -0.28856048  0.06232348 -0.53837043 -0.02680438\n",
      "  0.25243288  0.17937827 -0.8045986  -0.06188817  0.509764    0.0368312\n",
      "  0.234287    0.64654636  0.0503041   0.35679442 -0.04908825 -0.05642657\n",
      "  0.14914584 -0.22034179  0.15669699 -0.0416    ]\n",
      "0.48439866\n",
      "0.7834609\n",
      "[('margherita pizza', 0.8045516014099121), ('rosa pizza', 0.7795759439468384), ('caprina pizza', 0.7782953977584839), ('mushroom pizza', 0.7717488408088684), ('parmese pizza', 0.7647582292556763), ('siciliana pizza', 0.764582097530365), ('american pizza', 0.7628180384635925), ('sundried tomato', 0.7533938884735107), ('fiorentina pizza', 0.7502332329750061), ('napoletana pizza', 0.7443881630897522)]\n",
      "[('unclosedpizza', 0.9085118174552917), ('margherita pizza', 0.9009125232696533), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 0.8917295932769775), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#Rosa', 0.8862067461013794), ('unclosed', 0.8849341869354248), ('mushroom pizza', 0.8748230934143066), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#American', 0.8698841333389282), ('http://www.co-ode.org/ontologies/pizza/pizza.owl#UnclosedPizza', 0.868944525718689), ('rosa', 0.8688411712646484), ('rosa pizza', 0.8649780750274658)]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "#Embedding vectors generated above\n",
    "model = KeyedVectors.load(\"./cache/output/ontology.embeddings\", mmap='r')\n",
    "wv = model.wv\n",
    "\n",
    "vector = wv['pizza']  # Get numpy vector of a word\n",
    "print(\"Vector for 'pizza'\")\n",
    "print(vector)\n",
    "\n",
    "#cosine similarity\n",
    "similarity = wv.similarity('pizza', 'http://www.co-ode.org/ontologies/pizza/pizza.owl#Pizza')\n",
    "print(similarity)\n",
    "\n",
    "similarity = wv.similarity('http://www.co-ode.org/ontologies/pizza/pizza.owl#Margherita', 'margherita')\n",
    "print(similarity)\n",
    "\n",
    "\n",
    "#Most similar cosine similarity\n",
    "result = wv.most_similar(positive=['margherita', 'pizza'])\n",
    "print(result)\n",
    "\n",
    "#Most similar entities: cosmul\n",
    "result = wv.most_similar_cosmul(positive=['margherita'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cdbe3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
